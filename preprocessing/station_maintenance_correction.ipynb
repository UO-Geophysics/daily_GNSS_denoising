{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb10f292-0fa5-4f47-a2ef-a186e0d7cf47",
   "metadata": {},
   "source": [
    "# Detrend and clean dataset\n",
    "\n",
    "This notebook is used to detrend and clean dataset using the maintenance dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83d57a-06cc-4b31-a955-5a567ef15958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85e02a-2d03-451e-a55d-965083ee7cc9",
   "metadata": {},
   "source": [
    "### Read input file of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a01458-6c53-43bf-8354-e47c069f075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"../data/raw_daily_CWU.nc\").sel(time=slice(\"2010-01-01\", \"2024-01-01\"))\n",
    "ds = ds.dropna(dim=\"station\", how=\"all\", subset=['e'])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8937e-323a-46cf-a324-0810fd38b840",
   "metadata": {},
   "source": [
    "### Read maintenance log file in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f028689-e2d7-4824-bc73-5feb6d0e17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_parser(date_str):\n",
    "    return pd.to_datetime(date_str, format='%y%b%d')\n",
    "\n",
    "df = pd.read_csv(\"../data/maintenance_stations.txt\", delim_whitespace=True, header=None, nrows=15564, parse_dates=['date'],\n",
    "            date_parser=date_parser, names = ['station', 'date', 'number', 'operation'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfae01-710b-45a3-986f-8e197e231b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8556bff8-8c7f-4d85-96fb-2c4900e23964",
   "metadata": {},
   "source": [
    "# detrend with maintenance date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd6c7d-1de5-4560-8821-39e24525b8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def segment_data_by_maintenance(da, maintenance_dates, last_date=\"2024-01-01\"):\n",
    "    segments = []\n",
    "    prev_date = da['time'][0]\n",
    "    for date in maintenance_dates:\n",
    "        segment = da.sel({'time': slice(prev_date, date)})\n",
    "        if len(segment)>2:\n",
    "            segments.append(segment)\n",
    "            try:\n",
    "                prev_date = da['time'][da['time'] > date][0]\n",
    "            except:\n",
    "                prev_date = -1\n",
    "                # print(f\"error with next segment date for {segment}\")\n",
    "    #check final segment\n",
    "    if prev_date != -1:\n",
    "        segments.append(da.sel({'time': slice(prev_date, last_date)}))  # Final segment\n",
    "    return segments\n",
    "\n",
    "def detrend_dim(da, dim=\"time\", deg=1):\n",
    "    # detrend along a single dimension\n",
    "    p = da.polyfit(dim=dim, deg=deg)\n",
    "    fit = xr.polyval(da[dim], p.polyfit_coefficients)\n",
    "    return da - fit, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a05d30-45ce-4eec-b93c-d06bd193ac0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detrend_data_for_all_stations(data_array, df, dim=\"time\", deg=1):\n",
    "    detrended_data = []\n",
    "    trends = []\n",
    "    time = pd.date_range(start=data_array.time[0].item(), end=data_array.time[-1].item(), freq='1D')\n",
    "\n",
    "    for station in data_array[\"station\"].data:\n",
    "        # try:\n",
    "            station_data = data_array.sel(station=station)\n",
    "\n",
    "            if station in df[\"station\"].values:\n",
    "                maintenance_dates = df[df[\"station\"] == station].index\n",
    "                segments = segment_data_by_maintenance(station_data, maintenance_dates)\n",
    "            else:\n",
    "                # No maintenance dates for this station, consider the whole dataset as one segment\n",
    "                segments = [station_data]\n",
    "\n",
    "            detrended_station_segments = []\n",
    "            trend_station_segments = []\n",
    "            for segment in segments:\n",
    "                if len(segment) > 0:  # Check if the segment has data\n",
    "                    detrended, trend = detrend_dim(segment, dim=dim, deg=deg)\n",
    "                    detrended_station_segments.append(detrended)\n",
    "                    trend_station_segments.append(trend)\n",
    "\n",
    "            if len(detrended_station_segments) > 0:  # Check if there's valid detrended data\n",
    "                # Only concatenate if there's data to concatenate\n",
    "                detrended_da = xr.concat(detrended_station_segments, dim=dim).reindex(time=time)\n",
    "                trend_da = xr.concat(trend_station_segments, dim=dim).reindex(time=time)\n",
    "                detrended_data.append(detrended_da)\n",
    "                trends.append(trend_da)\n",
    "        # except:\n",
    "        #     print(f\"error with station {station}\")\n",
    "\n",
    "    # Concatenate all detrended data and trends into a single data array\n",
    "    if len(detrended_data) > 0:\n",
    "        detrended_combined = xr.concat(detrended_data, dim=\"station\")\n",
    "        trend_combined = xr.concat(trends, dim=\"station\")\n",
    "    else:\n",
    "        detrended_combined = xr.DataArray([], dims=[dim, \"station\"])\n",
    "        trend_combined = xr.DataArray([], dims=[dim, \"station\"])\n",
    "\n",
    "    return detrended_combined, trend_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee232d5-5306-4431-8a13-8a541d6f6e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_detrend, trends_n = detrend_data_for_all_stations(ds['n'], df)\n",
    "e_detrend, trends_e = detrend_data_for_all_stations(ds['e'], df)\n",
    "z_detrend, trends_z = detrend_data_for_all_stations(ds['z'], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a989479-ce5e-4087-9cad-ab681cf3e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = ('time', 'station')\n",
    "ds = ds.assign(variables={\"n_detrend\": (dims, n_detrend.data.T)})\n",
    "ds = ds.assign(variables={\"e_detrend\": (dims, e_detrend.data.T)})\n",
    "ds = ds.assign(variables={\"z_detrend\": (dims, z_detrend.data.T)})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cbf6cb-0d5d-4d60-82af-7241ce0ef71f",
   "metadata": {},
   "source": [
    "## Verification at one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35378e2-433b-4353-8866-ab1a7d6c4157",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_detrend.sel(station=\"ALBH\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7269eb71-49b8-4dd0-9ca1-70e8c8d1d84d",
   "metadata": {},
   "source": [
    "## Replace outliers and min max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efaa99b-d704-4a80-bcfb-0dd75e50cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(data, perc=0.99):\n",
    "    # calculate percentile\n",
    "    threshold = data.quantile(perc)\n",
    "    print(f\"threshold = {threshold.data}\")\n",
    "    # find outliers and replace them with nan\n",
    "    return data.where(abs(data)<=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62e426-8c29-474a-b4ff-268ad37b5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign(variables={\"n_clean\": (dims, replace_outliers(ds.n_detrend).data)})\n",
    "ds = ds.assign(variables={\"e_clean\": (dims, replace_outliers(ds.e_detrend).data)})\n",
    "ds = ds.assign(variables={\"z_clean\": (dims, replace_outliers(ds.z_detrend).data)})\n",
    "\n",
    "ds = ds.assign(variables={\"n_norm\": (dims, ((ds.n_clean.data-ds.n_clean.min().data)/(ds.n_clean.max().data-ds.n_clean.min().data))*2-1)})\n",
    "ds = ds.assign(variables={\"e_norm\": (dims, ((ds.e_clean.data-ds.e_clean.min().data)/(ds.e_clean.max().data-ds.e_clean.min().data))*2-1)})\n",
    "ds = ds.assign(variables={\"z_norm\": (dims, ((ds.z_clean.data-ds.z_clean.min().data)/(ds.z_clean.max().data-ds.z_clean.min().data))*2-1)})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939aad29-bff8-49b7-8a8d-42dc5da3e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "scalers = {'n':[ds.n_clean.min().data, ds.n_clean.max().data], \n",
    "           'e':[ds.e_clean.min().data, ds.e_clean.max().data], \n",
    "           'z':[ds.z_clean.min().data, ds.z_clean.max().data]}\n",
    "\n",
    "\n",
    "joblib.dump(scalers, \"./scalers_daily_CWU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417613d4-63ce-4084-9952-df1ae661895f",
   "metadata": {},
   "source": [
    "## Verrification at one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c508bc-42a7-445b-a1f3-18524cd55a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(station='ALBH').e_norm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56df28a-b4b3-4e57-80ca-fa7db47337d9",
   "metadata": {},
   "source": [
    "# save new ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f966a7-0902-440e-bedb-fecaf345e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(\"../data/clean_daily_pred_CWU.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d6810-7bab-4f48-b9c0-79d9a4377e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fit = xr.Dataset(\n",
    "            data_vars=dict(\n",
    "                n=([\"station\", \"time\"], trends_n.data),\n",
    "                e=([\"station\", \"time\"], trends_e.data),\n",
    "                z=([\"station\", \"time\"], trends_z.data),\n",
    "                ),\n",
    "            coords=dict(\n",
    "                station=([\"station\"], trends_n.station.data),\n",
    "                time=trends_n.time.data)\n",
    "            )\n",
    "ds_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5e869-1e9b-40d7-a097-a684ca087913",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fit.to_netcdf(\"./fit_daily_CWU.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GNSS_torch]",
   "language": "python",
   "name": "conda-env-GNSS_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
